{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bitgraph.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPb1J3bA7z98"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19vVRPY7l7tQ"
      },
      "source": [
        "i = 1.1e-05"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViRtGadH8i_e"
      },
      "source": [
        "distrans = {#'Year': [2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020],\n",
        "            'Transactions': [32741,185410,1902443,8459093,19645798,25265702,45689861,82634637,104081930,81393458,119729415,39978670],\n",
        "            'Inputs': [2810,108965,1902443,5716084,15407017,33300547,54564769,90773554,128642149,77568478,128768057,52805351],\n",
        "            'Outputs': [32643,143863,2595309,5981241,16278420,34586691,57150816,95783964,144361281,104780607,133558733,54179450],\n",
        "            'Max BTC’s in a tx': [22500,96999,550000,158336.30,194993.50,217517.63,172841.81,99489.99,87082.81,109735.6,157457.612,182501],\n",
        "            'Max inputs in a tx': [320,901,529,673,1757,674,1519,677,1089,1061,1347,1442],\n",
        "            'Max outputs in a tx': [2,98,2002,2792,3075,5352,13107,11515,6626,5027,7266,6990],\n",
        "            'Total BTCs sent': [1978736,22667790,297984085,925215501,429732306,264107039,548006072,1068404725,896026050.66,290858051.91,515972850.159,128637285.824],\n",
        "\n",
        "        }\n",
        "\n",
        "df = pd.DataFrame(distrans, columns = ['Transactions','Inputs','Outputs','Max BTC’s in a tx','Max inputs in a tx','Max outputs in a tx','Total BTCs sent'])\n",
        "\n",
        "print (df)\n",
        "\n",
        "\n",
        "table2 = {\n",
        "    'vertices': [32644,143943,2599119,6001831,16337189,34693993,57381025,57107986,78724132,53049193,32288199,3160555],\n",
        "    'edges': [32808,233872,4642054,19710026,49336100,78077032,145496703,29365348,625420597,330885984,230911982,24840651],\n",
        "    'simple_edge_density': [6.16,2.25,0.0128,0.034,0.0094,0.0037,0.00237,0.0052,0.0049,0.0068,0.0112,0.118],\n",
        "    'directed_edge_density': [3.08,1.12,0.0687,0.054,0.0185,0.00648,0.000442,0.009,0.0101,0.0117,0.0221,0.249]\n",
        "}\n",
        "\n",
        "df2 = pd.DataFrame(table2, columns = ['vertices','edges','simple_edge_density','directed_edge_density'])\n",
        "\n",
        "print (df2)\n",
        "\n",
        "\n",
        "table3 = {\n",
        "    'powerlaw_alpha_in': [1.99,1.54,2.35,1.86,1.88,1.98,2.12,2.1,2.11,1.92,2.4,2.2],\n",
        "    'exp_lambda_in': [0.11,0.001,0.011,0.004,0.002,0.002,0.0001,0.001,0.001,0.001,0.001,0.003],\n",
        "    'lognormal_mu_in': [1.79,2.59,-26.61,-52.63,-29.818218,-21.38,2.62,5.15,-194.65,-17.11,-398.36,-7.01],\n",
        "    'lognormal_alpha_in': [1.01,2.65,5.06,8.42,6.50,5.55,2.61,2.06,12.1,5.29,15.85,3.7],\n",
        "    'poisson_in': [13.83,4992.6,26133.67,43568.6,43778.7,7764.21,8610.67,7918,29039.39,63050.8,5095.25,4054.3],\n",
        "    'powerlaw_alpha_out': [1.33,1.42,1.73,1.74,1.85,1.86,1.87,1.77,2.58,2.34,2.7,2.07],\n",
        "    'exp_lambda_out': [0.25,0.06,0.013,0.005,0.002,0.002,0.001,0.001,0.001,0.0006,0.0007,0.0051],\n",
        "    'lognormal_mu_out': [7.27,4.52,52.81,7.835970,137.41132,18.89,1.25,7.3,7.76,4.8,-338.17,5.56],\n",
        "    'lognormal_alpha_out': [6.10,5.14,8.31,4.77,10.3,5.73,3.14,1.8,1.13,2.02,11.65,1.67],\n",
        "    'poisson_out': [10851.33,3754.7,4516.74,27558.8,24466.7,25145.02,14322.95,15859.95,5967.4,28175.95,5362.98,2580.6]\n",
        "}\n",
        "\n",
        "table3 = {\n",
        "    'diam': [0.03,0.03,0.06,0.06,0.05,0.05,0.09,0.11,0.1,0.11],\n",
        "    'avg_path': [0.05,0.03,0.06,0.06,0.05,0.05,0.09,0.11,0.1,0.11],\n",
        "    'recip': [0.02,0.008,0.2,0.16,0.03,0.019,0.016,0.003,0.0016,0.0009],\n",
        "    'assort': [-0.31,0.17,0.12,0.06,0.04,0.17,-0.026,-0.005,-0.022,0.28],\n",
        "    'central': [1,0.99,0.99,0.99,1,1,0.99,0.99,0.99,1],\n",
        "    'cd': [0.23,0.04,0.15,0.05,0.03,0.02,0.044,0.031,0.05,0.02],\n",
        "    'tri_lscc': [9580,104368,3797352,7751768,5140336,21461343,125423937,95674389,62367145,24089648],\n",
        "    'nodes_lscc': [34709,567144,2846171,6437119,10157747,17445491,10698736,9306342,3242666,844423],\n",
        "    'edges_lscc': [75367,1345036,13908941,32501745,41139689,85078065,120658573,169589795,62330136,18010394],\n",
        "    'ap_lscc': [72,638,1389,9270,14777,14790,1259,2206,717,522],\n",
        "    'C_lscc': [0.003,0.003,0.000091,0.0002,0.0008,0.0004,0.0015,0.0009,0.0004,0.004],\n",
        "    'tri_lwcc': [18708,3102649,4267711,7751768,6832830,25928531,213985326,210765433,214016097,88648952],\n",
        "    'nodes_lwcc': [143880,2593961,5979901,16282225,34556782,57084066,53556287,74366786,47785524,26470992],\n",
        "    'edges_lwcc': [233829,4638181,19693726,49292728,77961419,145254102,287695383,618579809,325783461,212922543],\n",
        "    'ap_lwcc': [20774,496060,1440988,4282322,7775376,13682985,5333181,6854728,4535938,3167225],\n",
        "    'C_lwcc': [0.0000111,0.0005,0.0001,0.0002,0.0001,0.0002,0.0005,0.0003,0.0001,0.0004],\n",
        "    'tri_full': [18709,3102700,4267910,9102472,6834251,25931343,214055511,287646955,214094259,88721557],\n",
        "    'nodes_full': [20784,497641,1447747,4297982,7809891,13771043,6212728,6987676,5488866,4060330],\n",
        "    'edges_full': [0.0000111,0.0005,0.0001,0.0002,0.0001,0.0002,0.0005,0.0003,0.0001,0.0004],\n",
        "    'cores_lscc': [9930,120262,1065542,347630,333420,601493,146836,72718,272896,1154252],\n",
        "    'cores_lwcc': [10964,120262,1065542,347630,333420,601493,112356,72718,272896,1154252],\n",
        "    'core_full': [10964,120262,1065542,347630,333420,601493,112356,72718,272896,1154252]\n",
        "}\n",
        "\n",
        "df3 = pd.DataFrame(table3)\n",
        "\n",
        "print (df3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEu-ppEI_6g5"
      },
      "source": [
        "plot_cols = df.columns.tolist()\n",
        "plot_features = df[plot_cols]\n",
        "plot_features.index = df.index\n",
        "_ = plot_features.plot(subplots=True)\n",
        "plt.savefig('test2png.png', dpi=300,bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkzrVZdkwEYE"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(df3)\n",
        "unscaled = scaler.inverse_transform(scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOfW_tKUxSZ4"
      },
      "source": [
        "df3 = pd.DataFrame(scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdeLBaC0Fv51"
      },
      "source": [
        "column_indices = {name: i for i, name in enumerate(df3.columns)}\n",
        "\n",
        "n = len(df3)\n",
        "train_df = df3[0:int(n*0.5)]\n",
        "val_df = df3[int(n*0.5):int(n*0.7)]\n",
        "test_df = df3[int(n*0.7):]\n",
        "\n",
        "num_features = df3.shape[1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqtVx6XgF9kc"
      },
      "source": [
        "train_mean = train_df.mean()\n",
        "train_std = train_df.std()\n",
        "\n",
        "train_df = (train_df - train_mean) / train_std\n",
        "val_df = (val_df - train_mean) / train_std\n",
        "test_df = (test_df - train_mean) / train_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTwuwv62GIwJ"
      },
      "source": [
        "class WindowGenerator():\n",
        "  def __init__(self, input_width, label_width, shift,\n",
        "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
        "               label_columns=None):\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # Work out the label column indices.\n",
        "    self.label_columns = label_columns\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoHSjRMPGKMT"
      },
      "source": [
        "def split_window(self, features):\n",
        "  inputs = features[:, self.input_slice, :]\n",
        "  labels = features[:, self.labels_slice, :]\n",
        "  if self.label_columns is not None:\n",
        "    labels = tf.stack(\n",
        "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "        axis=-1)\n",
        "\n",
        "  # Slicing doesn't preserve static shape information, so set the shapes\n",
        "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "  inputs.set_shape([None, self.input_width, None])\n",
        "  labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "  return inputs, labels\n",
        "\n",
        "WindowGenerator.split_window = split_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T4zC711GSEH"
      },
      "source": [
        "def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n",
        "  inputs, labels = self.example\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plot_col_index = self.column_indices[plot_col]\n",
        "  max_n = min(max_subplots, len(inputs))\n",
        "  for n in range(max_n):\n",
        "    plt.subplot(3, 1, n+1)\n",
        "    plt.ylabel(f'{plot_col} [normed]')\n",
        "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
        "             label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "    if self.label_columns:\n",
        "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "    else:\n",
        "      label_col_index = plot_col_index\n",
        "\n",
        "    if label_col_index is None:\n",
        "      continue\n",
        "\n",
        "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
        "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "    if model is not None:\n",
        "      predictions = model(inputs)\n",
        "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
        "                  marker='X', edgecolors='k', label='Predictions',\n",
        "                  c='#ff7f0e', s=64)\n",
        "\n",
        "    if n == 0:\n",
        "      plt.legend()\n",
        "\n",
        "  plt.xlabel('Time [h]')\n",
        "\n",
        "WindowGenerator.plot = plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyXyfdFGGsQy"
      },
      "source": [
        "def make_dataset(self, data):\n",
        "  data = np.array(data, dtype=np.float32)\n",
        "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "      data=data,\n",
        "      targets=None,\n",
        "      sequence_length=self.total_window_size,\n",
        "      sequence_stride=1,\n",
        "      shuffle=True,\n",
        "      batch_size=32,)\n",
        "\n",
        "  ds = ds.map(self.split_window)\n",
        "\n",
        "  return ds\n",
        "\n",
        "WindowGenerator.make_dataset = make_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFLUHWMbGtIs"
      },
      "source": [
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "\n",
        "@property\n",
        "def val(self):\n",
        "  return self.make_dataset(self.val_df)\n",
        "\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "\n",
        "@property\n",
        "def example(self):\n",
        "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "  result = getattr(self, '_example', None)\n",
        "  if result is None:\n",
        "    # No example batch was found, so get one from the `.train` dataset\n",
        "    result = next(iter(self.train))\n",
        "    # And cache it for next time\n",
        "    self._example = result\n",
        "  return result\n",
        "\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.val = val\n",
        "WindowGenerator.test = test\n",
        "WindowGenerator.example = example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXcAL0bhG1gY"
      },
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    input_width=1, label_width=1, shift=1\n",
        ")\n",
        "single_step_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPdeGSkXIVoO"
      },
      "source": [
        "linear = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGiV45FEIYnX"
      },
      "source": [
        "MAX_EPOCHS = 20\n",
        "\n",
        "def compile_and_fit(model, window, patience=2):\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min')\n",
        "\n",
        "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
        "                      validation_data=window.val,\n",
        "                      callbacks=[early_stopping])\n",
        "  return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRID8tDeIZoK"
      },
      "source": [
        "history = compile_and_fit(linear, single_step_window)\n",
        "\n",
        "val_performance = {}\n",
        "performance = {}\n",
        "\n",
        "val_performance['Linear'] = linear.evaluate(single_step_window.val)\n",
        "performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7sZqEc0Ps1W"
      },
      "source": [
        "for example_inputs, example_labels in single_step_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96yv9_CJIqZi"
      },
      "source": [
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(dense, single_step_window)\n",
        "\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8nwy-roKNFU"
      },
      "source": [
        "conv_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=32,\n",
        "                           kernel_size=(1,),\n",
        "                           activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=num_features),\n",
        "])\n",
        "history = compile_and_fit(conv_model, single_step_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Conv'] = conv_model.evaluate(single_step_window.val)\n",
        "performance['Conv'] = conv_model.evaluate(single_step_window.test, verbose=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53yCueNsK-cE"
      },
      "source": [
        "\n",
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(lstm_model, single_step_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate(single_step_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate( single_step_window.test, verbose=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNfM4XaaLij1"
      },
      "source": [
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.ylabel('mean_absolute_error [T (degC), normalized]')\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(),\n",
        "           rotation=45)\n",
        "_ = plt.legend()\n",
        "plt.savefig('perf.png', dpi=300,bbox_inches='tight', pad_inches=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wHFfKPRLrre"
      },
      "source": [
        "last = df3.iloc[9].to_numpy()\n",
        "\n",
        "newarr = last.reshape(-1,1,num_features)\n",
        "\n",
        "preds = lstm_model.predict(newarr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w_T95g2x6Xu"
      },
      "source": [
        "preds = preds.reshape(1,22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzVkCKFFxzyy"
      },
      "source": [
        "unscaled = scaler.inverse_transform(preds)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}